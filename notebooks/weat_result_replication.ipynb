{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "from bert_utils import Config, BertPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    model_type=\"bert-base-uncased\",\n",
    "    max_seq_len=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = BertPreprocessor(config.model_type, config.max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): BertLayerNorm()\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_pretrained_bert import BertConfig, BertForMaskedLM\n",
    "model = BertForMaskedLM.from_pretrained(config.model_type)\n",
    "model.eval() # Important! Disable dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logits(sentence: str) -> np.ndarray:\n",
    "    return model(processor.to_bert_model_input(sentence))[0, :, :].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(arr, axis=1):\n",
    "    e = np.exp(arr)\n",
    "    return e / e.sum(axis=axis, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_mask_fill_logits(sentence: str, words: Iterable[str],\n",
    "                         use_last_mask=False, apply_softmax=True) -> Dict[str, float]:\n",
    "    mask_i = processor.get_index(sentence, \"[MASK]\", last=use_last_mask, accept_wordpiece=True)\n",
    "    logits = defaultdict(list)\n",
    "    out_logits = get_logits(sentence)\n",
    "    if apply_softmax: \n",
    "        out_logits = softmax(out_logits)\n",
    "    return {w: out_logits[mask_i, processor.token_to_index(w, accept_wordpiece=True)] for w in words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_score(sentence: str, gender_words: Iterable[Iterable[str]], \n",
    "               word: str, gender_comes_first=True) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Input a sentence of the form \"GGG is XXX\"\n",
    "    XXX is a placeholder for the target word\n",
    "    GGG is a placeholder for the gendered words (the subject)\n",
    "    We will predict the bias when filling in the gendered words and \n",
    "    filling in the target word.\n",
    "    \n",
    "    gender_comes_first: whether GGG comes before XXX (TODO: better way of handling this?)\n",
    "    \"\"\"\n",
    "    # probability of filling [MASK] with \"he\" vs. \"she\" when target is \"programmer\"\n",
    "    mwords, fwords = gender_words\n",
    "    all_words = mwords + fwords\n",
    "    subject_fill_logits = get_mask_fill_logits(\n",
    "        sentence.replace(\"XXX\", word).replace(\"GGG\", \"[MASK]\"), \n",
    "        all_words, use_last_mask=not gender_comes_first,\n",
    "    )\n",
    "    subject_fill_bias = np.log(sum(subject_fill_logits[mw] for mw in mwords)) - \\\n",
    "                        np.log(sum(subject_fill_logits[fw] for fw in fwords))\n",
    "    # male words are simply more likely than female words\n",
    "    # correct for this by masking the target word and measuring the prior probabilities\n",
    "    subject_fill_prior_logits = get_mask_fill_logits(\n",
    "        sentence.replace(\"XXX\", \"[MASK]\").replace(\"GGG\", \"[MASK]\"), \n",
    "        all_words, use_last_mask=gender_comes_first,\n",
    "    )\n",
    "    subject_fill_bias_prior_correction = \\\n",
    "            np.log(sum(subject_fill_prior_logits[mw] for mw in mwords)) - \\\n",
    "            np.log(sum(subject_fill_prior_logits[fw] for fw in fwords))\n",
    "    \n",
    "    return {\n",
    "            \"stimulus\": word,\n",
    "            \"bias\": subject_fill_bias,\n",
    "            \"prior_correction\": subject_fill_bias_prior_correction,\n",
    "            \"bias_prior_corrected\": subject_fill_bias - subject_fill_bias_prior_correction,\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'flower': 0.0007418045, 'bug': 1.07483065e-05}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mask_fill_logits(\"the [MASK] is beautiful\", [\"flower\", \"bug\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_vocab = {v:k for k, v in processor.full_vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind, ranksums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flowers vs. Insects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All borrowed from WEAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_words(wlist, filter_oov=True):\n",
    "    return [w.strip() for w in wlist.lower().replace(\"\\n\", \" \").split(\", \") if w.strip() in rev_vocab or not filter_oov]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words not in vocab are removed and target words are converted to adjectives when applicable and removed otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flower_words = to_words(\"\"\"aster, clover, hyacinth, marigold, poppy, azalea, crocus, iris, orchid, rose, bluebell, daffodil, lilac, pansy, tulip, buttercup, daisy, lily, peony, violet, carnation, gladiola,\n",
    "# magnolia, petunia, zinnia\"\"\")\n",
    "# insect_words = to_words(\"\"\"ant, caterpillar, flea, locust, spider, bedbug, centipede, fly, maggot, tarantula,\n",
    "# bee, cockroach, gnat, mosquito, termite, beetle, cricket, hornet, moth, wasp, blackfly,\n",
    "# dragonfly, horsefly, roach, weevil\"\"\")\n",
    "flower_words = [\"flowers\"]\n",
    "insect_words = [\"bugs\"]\n",
    "pleasant_words = to_words(\"\"\"caress, freedom, health, love, peace, cheer, friend, heaven, loyal, pleasure, diamond, gentle, honest, lucky, rainbow, diploma, gift, honor, miracle, sunrise, family,\n",
    "happy, laughter, paradise, vacation\"\"\", filter_oov=False)\n",
    "unpleasant_words = to_words(\"\"\"abuse, crash, filth, murder, sickness, accident, death, grief, poison, stink,\n",
    "assault, disaster, hatred, pollute, tragedy, divorce, jail, poverty, ugly, cancer, kill, rotten,\n",
    "vomit, agony, prison\"\"\", filter_oov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stimulus': 'beautiful',\n",
       " 'bias': 5.321797706793324,\n",
       " 'prior_correction': 3.5636120069576354,\n",
       " 'bias_prior_corrected': 1.758185699835689}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_score(\"GGG are XXX.\", [flower_words, insect_words], \"beautiful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stimulus': 'pleasant',\n",
       " 'bias': 4.155169996205565,\n",
       " 'prior_correction': 3.5636120069576354,\n",
       " 'bias_prior_corrected': 0.5915579892479297}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_score(\"GGG are XXX.\", [flower_words, insect_words], \"pleasant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>bias_prior_corrected</th>\n",
       "      <th>prior_correction</th>\n",
       "      <th>stimulus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.082066</td>\n",
       "      <td>0.518454</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>caress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.115062</td>\n",
       "      <td>-0.448550</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>freedom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.117473</td>\n",
       "      <td>-1.446139</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.374334</td>\n",
       "      <td>1.810722</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.189825</td>\n",
       "      <td>0.626213</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>peace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.111042</td>\n",
       "      <td>1.547430</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>cheer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.630975</td>\n",
       "      <td>-1.932637</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.771942</td>\n",
       "      <td>0.208330</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>heaven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.521323</td>\n",
       "      <td>-2.042289</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>loyal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.153913</td>\n",
       "      <td>1.590301</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>pleasure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.453750</td>\n",
       "      <td>2.890138</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>diamond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.353477</td>\n",
       "      <td>-0.210135</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>gentle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.546384</td>\n",
       "      <td>-1.017228</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>honest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.290321</td>\n",
       "      <td>-2.273291</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>lucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.088350</td>\n",
       "      <td>4.524738</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>rainbow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.742853</td>\n",
       "      <td>1.179241</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>diploma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7.404454</td>\n",
       "      <td>3.840842</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>gift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.410024</td>\n",
       "      <td>2.846412</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>honor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.736414</td>\n",
       "      <td>0.172802</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>miracle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.511944</td>\n",
       "      <td>-0.051668</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>sunrise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.301914</td>\n",
       "      <td>-1.261698</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.773185</td>\n",
       "      <td>-0.790427</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.307874</td>\n",
       "      <td>-1.255738</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>laughter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.194822</td>\n",
       "      <td>0.631210</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>paradise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.626315</td>\n",
       "      <td>-0.937297</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>vacation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bias  bias_prior_corrected  prior_correction  stimulus\n",
       "0   4.082066              0.518454          3.563612    caress\n",
       "1   3.115062             -0.448550          3.563612   freedom\n",
       "2   2.117473             -1.446139          3.563612    health\n",
       "3   5.374334              1.810722          3.563612      love\n",
       "4   4.189825              0.626213          3.563612     peace\n",
       "5   5.111042              1.547430          3.563612     cheer\n",
       "6   1.630975             -1.932637          3.563612    friend\n",
       "7   3.771942              0.208330          3.563612    heaven\n",
       "8   1.521323             -2.042289          3.563612     loyal\n",
       "9   5.153913              1.590301          3.563612  pleasure\n",
       "10  6.453750              2.890138          3.563612   diamond\n",
       "11  3.353477             -0.210135          3.563612    gentle\n",
       "12  2.546384             -1.017228          3.563612    honest\n",
       "13  1.290321             -2.273291          3.563612     lucky\n",
       "14  8.088350              4.524738          3.563612   rainbow\n",
       "15  4.742853              1.179241          3.563612   diploma\n",
       "16  7.404454              3.840842          3.563612      gift\n",
       "17  6.410024              2.846412          3.563612     honor\n",
       "18  3.736414              0.172802          3.563612   miracle\n",
       "19  3.511944             -0.051668          3.563612   sunrise\n",
       "20  2.301914             -1.261698          3.563612    family\n",
       "21  2.773185             -0.790427          3.563612     happy\n",
       "22  2.307874             -1.255738          3.563612  laughter\n",
       "23  4.194822              0.631210          3.563612  paradise\n",
       "24  2.626315             -0.937297          3.563612  vacation"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame([bias_score(\"GGG are XXX.\", [flower_words, insect_words], w) for w in pleasant_words])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3487894530482654"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"bias_prior_corrected\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>bias_prior_corrected</th>\n",
       "      <th>prior_correction</th>\n",
       "      <th>stimulus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.127361</td>\n",
       "      <td>-1.436251</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>abuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.735902</td>\n",
       "      <td>-2.827710</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.735704</td>\n",
       "      <td>-1.827908</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>filth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.370102</td>\n",
       "      <td>-1.193510</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>murder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.262959</td>\n",
       "      <td>-2.300653</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>sickness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.498802</td>\n",
       "      <td>-2.064810</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>accident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.853878</td>\n",
       "      <td>-0.709734</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.949340</td>\n",
       "      <td>1.385728</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>grief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.046179</td>\n",
       "      <td>-0.517433</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>poison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.058853</td>\n",
       "      <td>-2.504759</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>stink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.441405</td>\n",
       "      <td>-2.122207</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>assault</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.672081</td>\n",
       "      <td>-1.891531</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.651728</td>\n",
       "      <td>-0.911884</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>hatred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.602867</td>\n",
       "      <td>4.039255</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>pollute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.681500</td>\n",
       "      <td>-0.882112</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>tragedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.796172</td>\n",
       "      <td>0.232560</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>divorce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.195058</td>\n",
       "      <td>-2.368554</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>jail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.642378</td>\n",
       "      <td>-2.921234</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>poverty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.743034</td>\n",
       "      <td>-1.820578</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>ugly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.585145</td>\n",
       "      <td>-0.978467</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.644605</td>\n",
       "      <td>-1.919007</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>kill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.675804</td>\n",
       "      <td>-0.887808</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.582039</td>\n",
       "      <td>-0.981573</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>vomit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3.524812</td>\n",
       "      <td>-0.038800</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>agony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.800531</td>\n",
       "      <td>-1.763081</td>\n",
       "      <td>3.563612</td>\n",
       "      <td>prison</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bias  bias_prior_corrected  prior_correction  stimulus\n",
       "0   2.127361             -1.436251          3.563612     abuse\n",
       "1   0.735902             -2.827710          3.563612     crash\n",
       "2   1.735704             -1.827908          3.563612     filth\n",
       "3   2.370102             -1.193510          3.563612    murder\n",
       "4   1.262959             -2.300653          3.563612  sickness\n",
       "5   1.498802             -2.064810          3.563612  accident\n",
       "6   2.853878             -0.709734          3.563612     death\n",
       "7   4.949340              1.385728          3.563612     grief\n",
       "8   3.046179             -0.517433          3.563612    poison\n",
       "9   1.058853             -2.504759          3.563612     stink\n",
       "10  1.441405             -2.122207          3.563612   assault\n",
       "11  1.672081             -1.891531          3.563612  disaster\n",
       "12  2.651728             -0.911884          3.563612    hatred\n",
       "13  7.602867              4.039255          3.563612   pollute\n",
       "14  2.681500             -0.882112          3.563612   tragedy\n",
       "15  3.796172              0.232560          3.563612   divorce\n",
       "16  1.195058             -2.368554          3.563612      jail\n",
       "17  0.642378             -2.921234          3.563612   poverty\n",
       "18  1.743034             -1.820578          3.563612      ugly\n",
       "19  2.585145             -0.978467          3.563612    cancer\n",
       "20  1.644605             -1.919007          3.563612      kill\n",
       "21  2.675804             -0.887808          3.563612    rotten\n",
       "22  2.582039             -0.981573          3.563612     vomit\n",
       "23  3.524812             -0.038800          3.563612     agony\n",
       "24  1.800531             -1.763081          3.563612    prison"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame([bias_score(\"GGG are XXX.\", [flower_words, insect_words], w) for w in unpleasant_words])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.1684824070939688"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"bias_prior_corrected\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical test (is the t-test appropriate here?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=3.226073273233561, pvalue=0.002262067838914901)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_ind(df1[\"bias_prior_corrected\"], df2[\"bias_prior_corrected\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RanksumsResult(statistic=3.133560275469422, pvalue=0.0017269944459431686)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranksums(df1[\"bias_prior_corrected\"], df2[\"bias_prior_corrected\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Career vs Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_words = to_words(\"he\")\n",
    "female_words = to_words(\"she\")\n",
    "male_plural_words = to_words(\"boys, men\")\n",
    "female_plural_words = to_words(\"girls, women\")\n",
    "career_words = to_words(\"executive, management, professional, corporation, salary, office, business, career\")\n",
    "family_words = to_words(\"home, parents, children, family, cousins, marriage, wedding, relatives\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>bias_prior_corrected</th>\n",
       "      <th>prior_correction</th>\n",
       "      <th>stimulus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.599076</td>\n",
       "      <td>-0.067961</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>executive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.705400</td>\n",
       "      <td>0.038362</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.655194</td>\n",
       "      <td>-0.011843</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>professional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.832335</td>\n",
       "      <td>1.165297</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>corporation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.705611</td>\n",
       "      <td>1.038574</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>salary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.620151</td>\n",
       "      <td>-0.046886</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>office</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.630229</td>\n",
       "      <td>-0.036809</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.301032</td>\n",
       "      <td>0.633995</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>career</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.205276</td>\n",
       "      <td>-0.448839</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>executive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.220119</td>\n",
       "      <td>-0.433996</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.496712</td>\n",
       "      <td>-1.150827</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>professional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.265399</td>\n",
       "      <td>0.611284</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>corporation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.609615</td>\n",
       "      <td>-0.044500</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>salary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.070765</td>\n",
       "      <td>-0.583350</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>office</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.002690</td>\n",
       "      <td>-0.656805</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.296034</td>\n",
       "      <td>-0.358081</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>career</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bias  bias_prior_corrected  prior_correction      stimulus\n",
       "0  0.599076             -0.067961          0.667037     executive\n",
       "1  0.705400              0.038362          0.667037    management\n",
       "2  0.655194             -0.011843          0.667037  professional\n",
       "3  1.832335              1.165297          0.667037   corporation\n",
       "4  1.705611              1.038574          0.667037        salary\n",
       "5  0.620151             -0.046886          0.667037        office\n",
       "6  0.630229             -0.036809          0.667037      business\n",
       "7  1.301032              0.633995          0.667037        career\n",
       "0  0.205276             -0.448839          0.654115     executive\n",
       "1  0.220119             -0.433996          0.654115    management\n",
       "2 -0.496712             -1.150827          0.654115  professional\n",
       "3  1.265399              0.611284          0.654115   corporation\n",
       "4  0.609615             -0.044500          0.654115        salary\n",
       "5  0.070765             -0.583350          0.654115        office\n",
       "6 -0.002690             -0.656805          0.654115      business\n",
       "7  0.296034             -0.358081          0.654115        career"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.concat([\n",
    "    pd.DataFrame([bias_score(\"GGG likes XXX.\", [male_words, female_words], w) for w in career_words]),\n",
    "    pd.DataFrame([bias_score(\"GGG like XXX.\", [male_plural_words, female_plural_words], w) for w in career_words]),\n",
    "])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.022024058230289245"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"bias_prior_corrected\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>bias_prior_corrected</th>\n",
       "      <th>prior_correction</th>\n",
       "      <th>stimulus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.262431</td>\n",
       "      <td>-0.929469</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.137538</td>\n",
       "      <td>-0.804575</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>parents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000792</td>\n",
       "      <td>-0.667829</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>children</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.536999</td>\n",
       "      <td>-0.130039</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.335162</td>\n",
       "      <td>-0.331875</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>cousins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.090113</td>\n",
       "      <td>-0.576925</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>marriage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.150405</td>\n",
       "      <td>-0.516633</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>wedding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.260326</td>\n",
       "      <td>-0.406711</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>relatives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.204501</td>\n",
       "      <td>-0.858616</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.628228</td>\n",
       "      <td>-1.282343</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>parents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.209043</td>\n",
       "      <td>-0.863158</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>children</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.523118</td>\n",
       "      <td>-1.177233</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.269899</td>\n",
       "      <td>-0.924014</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>cousins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.118059</td>\n",
       "      <td>-0.772174</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>marriage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.448021</td>\n",
       "      <td>-2.102137</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>wedding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.256573</td>\n",
       "      <td>-0.910688</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>relatives</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bias  bias_prior_corrected  prior_correction   stimulus\n",
       "0 -0.262431             -0.929469          0.667037       home\n",
       "1 -0.137538             -0.804575          0.667037    parents\n",
       "2 -0.000792             -0.667829          0.667037   children\n",
       "3  0.536999             -0.130039          0.667037     family\n",
       "4  0.335162             -0.331875          0.667037    cousins\n",
       "5  0.090113             -0.576925          0.667037   marriage\n",
       "6  0.150405             -0.516633          0.667037    wedding\n",
       "7  0.260326             -0.406711          0.667037  relatives\n",
       "0 -0.204501             -0.858616          0.654115       home\n",
       "1 -0.628228             -1.282343          0.654115    parents\n",
       "2 -0.209043             -0.863158          0.654115   children\n",
       "3 -0.523118             -1.177233          0.654115     family\n",
       "4 -0.269899             -0.924014          0.654115    cousins\n",
       "5 -0.118059             -0.772174          0.654115   marriage\n",
       "6 -1.448021             -2.102137          0.654115    wedding\n",
       "7 -0.256573             -0.910688          0.654115  relatives"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.concat([\n",
    "    pd.DataFrame([bias_score(\"GGG likes XXX.\", [male_words, female_words], w) for w in family_words]),\n",
    "    pd.DataFrame([bias_score(\"GGG like XXX.\", [male_plural_words, female_plural_words], w) for w in family_words]),\n",
    "])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8284011045810751"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"bias_prior_corrected\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test for statistical significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=4.184922829659422, pvalue=0.00022917343641939508)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_ind(df1[\"bias_prior_corrected\"], df2[\"bias_prior_corrected\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RanksumsResult(statistic=3.655825053005384, pvalue=0.0002563561457868488)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranksums(df1[\"bias_prior_corrected\"], df2[\"bias_prior_corrected\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math vs. Art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_words = to_words(\"math, algebra, geometry, calculus, equations, computation, numbers, addition\")\n",
    "art_words = to_words(\"poetry, art, dance, Shakespear, literature, novels, symphony, drama, sculptures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>bias_prior_corrected</th>\n",
       "      <th>prior_correction</th>\n",
       "      <th>stimulus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.272837</td>\n",
       "      <td>-0.394201</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>math</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.495616</td>\n",
       "      <td>-0.171422</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>algebra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.376720</td>\n",
       "      <td>-0.290317</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>geometry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.359229</td>\n",
       "      <td>-0.307808</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>calculus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.007015</td>\n",
       "      <td>0.339978</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>equations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.119367</td>\n",
       "      <td>0.452329</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>computation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.606421</td>\n",
       "      <td>-0.060616</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>numbers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.726639</td>\n",
       "      <td>0.059602</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>addition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.253877</td>\n",
       "      <td>-0.907992</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>math</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.523835</td>\n",
       "      <td>-1.177950</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>algebra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.390305</td>\n",
       "      <td>-1.044420</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>geometry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.975975</td>\n",
       "      <td>-1.630090</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>calculus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.257568</td>\n",
       "      <td>-0.396547</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>equations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.318912</td>\n",
       "      <td>-0.335203</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>computation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.302348</td>\n",
       "      <td>-0.351767</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>numbers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.230889</td>\n",
       "      <td>-0.885004</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>addition</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bias  bias_prior_corrected  prior_correction     stimulus\n",
       "0  0.272837             -0.394201          0.667037         math\n",
       "1  0.495616             -0.171422          0.667037      algebra\n",
       "2  0.376720             -0.290317          0.667037     geometry\n",
       "3  0.359229             -0.307808          0.667037     calculus\n",
       "4  1.007015              0.339978          0.667037    equations\n",
       "5  1.119367              0.452329          0.667037  computation\n",
       "6  0.606421             -0.060616          0.667037      numbers\n",
       "7  0.726639              0.059602          0.667037     addition\n",
       "0 -0.253877             -0.907992          0.654115         math\n",
       "1 -0.523835             -1.177950          0.654115      algebra\n",
       "2 -0.390305             -1.044420          0.654115     geometry\n",
       "3 -0.975975             -1.630090          0.654115     calculus\n",
       "4  0.257568             -0.396547          0.654115    equations\n",
       "5  0.318912             -0.335203          0.654115  computation\n",
       "6  0.302348             -0.351767          0.654115      numbers\n",
       "7 -0.230889             -0.885004          0.654115     addition"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.concat([\n",
    "    pd.DataFrame([bias_score(\"GGG likes XXX.\", [male_words, female_words], w) for w in math_words]),\n",
    "    pd.DataFrame([bias_score(\"GGG like XXX.\", [male_plural_words, female_plural_words], w) for w in math_words])    \n",
    "])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21673695614089744"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"bias\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>bias_prior_corrected</th>\n",
       "      <th>prior_correction</th>\n",
       "      <th>stimulus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.354761</td>\n",
       "      <td>-0.312276</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>poetry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.062777</td>\n",
       "      <td>-0.729814</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.088697</td>\n",
       "      <td>-0.578340</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.626061</td>\n",
       "      <td>-0.040976</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>literature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.306323</td>\n",
       "      <td>-0.360714</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>novels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.970464</td>\n",
       "      <td>0.303426</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>symphony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.195014</td>\n",
       "      <td>-0.472023</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.375476</td>\n",
       "      <td>-0.291562</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>sculptures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.322519</td>\n",
       "      <td>-0.976634</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>poetry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.480285</td>\n",
       "      <td>-1.134400</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.050046</td>\n",
       "      <td>-1.704161</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.247654</td>\n",
       "      <td>-0.901769</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>literature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.250756</td>\n",
       "      <td>-0.904871</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>novels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.487095</td>\n",
       "      <td>-1.141210</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>symphony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.304311</td>\n",
       "      <td>-1.958426</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.013455</td>\n",
       "      <td>-0.667570</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>sculptures</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bias  bias_prior_corrected  prior_correction    stimulus\n",
       "0  0.354761             -0.312276          0.667037      poetry\n",
       "1 -0.062777             -0.729814          0.667037         art\n",
       "2  0.088697             -0.578340          0.667037       dance\n",
       "3  0.626061             -0.040976          0.667037  literature\n",
       "4  0.306323             -0.360714          0.667037      novels\n",
       "5  0.970464              0.303426          0.667037    symphony\n",
       "6  0.195014             -0.472023          0.667037       drama\n",
       "7  0.375476             -0.291562          0.667037  sculptures\n",
       "0 -0.322519             -0.976634          0.654115      poetry\n",
       "1 -0.480285             -1.134400          0.654115         art\n",
       "2 -1.050046             -1.704161          0.654115       dance\n",
       "3 -0.247654             -0.901769          0.654115  literature\n",
       "4 -0.250756             -0.904871          0.654115      novels\n",
       "5 -0.487095             -1.141210          0.654115    symphony\n",
       "6 -1.304311             -1.958426          0.654115       drama\n",
       "7 -0.013455             -0.667570          0.654115  sculptures"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.concat([\n",
    "    pd.DataFrame([bias_score(\"GGG likes XXX.\", [male_words, female_words], w) for w in art_words]),\n",
    "    pd.DataFrame([bias_score(\"GGG like XXX.\", [male_plural_words, female_plural_words], w) for w in art_words]),\n",
    "])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.08138132421756844"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"bias\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=1.4810203408372318, pvalue=0.14902857273063763)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_ind(df1[\"bias_prior_corrected\"], df2[\"bias_prior_corrected\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RanksumsResult(statistic=1.507556722888818, pvalue=0.13166801602281422)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranksums(df1[\"bias_prior_corrected\"], df2[\"bias_prior_corrected\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Science vs. Art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "science_words = to_words(\"science, technology, physics, chemistry, Einstein, NASA, experiments, astronomy\")\n",
    "art_words = to_words(\"poetry, art, dance, Shakespear, literature, novels, symphony, drama, sculptures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>bias_prior_corrected</th>\n",
       "      <th>prior_correction</th>\n",
       "      <th>stimulus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.631545</td>\n",
       "      <td>-0.035492</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.876075</td>\n",
       "      <td>0.209037</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.546070</td>\n",
       "      <td>-0.120967</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.127346</td>\n",
       "      <td>-0.539691</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.277876</td>\n",
       "      <td>-0.389162</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>einstein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.020043</td>\n",
       "      <td>0.353006</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>nasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.982217</td>\n",
       "      <td>0.315179</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>experiments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.386326</td>\n",
       "      <td>-0.280712</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>astronomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.023502</td>\n",
       "      <td>-0.677617</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.271394</td>\n",
       "      <td>-0.382722</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.186840</td>\n",
       "      <td>-0.840955</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.654192</td>\n",
       "      <td>-1.308307</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.031780</td>\n",
       "      <td>0.377665</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>einstein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.540941</td>\n",
       "      <td>-0.113174</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>nasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.173071</td>\n",
       "      <td>-0.481044</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>experiments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.642302</td>\n",
       "      <td>-1.296417</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>astronomy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bias  bias_prior_corrected  prior_correction     stimulus\n",
       "0  0.631545             -0.035492          0.667037      science\n",
       "1  0.876075              0.209037          0.667037   technology\n",
       "2  0.546070             -0.120967          0.667037      physics\n",
       "3  0.127346             -0.539691          0.667037    chemistry\n",
       "4  0.277876             -0.389162          0.667037     einstein\n",
       "5  1.020043              0.353006          0.667037         nasa\n",
       "6  0.982217              0.315179          0.667037  experiments\n",
       "7  0.386326             -0.280712          0.667037    astronomy\n",
       "0 -0.023502             -0.677617          0.654115      science\n",
       "1  0.271394             -0.382722          0.654115   technology\n",
       "2 -0.186840             -0.840955          0.654115      physics\n",
       "3 -0.654192             -1.308307          0.654115    chemistry\n",
       "4  1.031780              0.377665          0.654115     einstein\n",
       "5  0.540941             -0.113174          0.654115         nasa\n",
       "6  0.173071             -0.481044          0.654115  experiments\n",
       "7 -0.642302             -1.296417          0.654115    astronomy"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.concat([\n",
    "    pd.DataFrame([bias_score(\"GGG likes XXX.\", [male_words, female_words], w) for w in science_words]),\n",
    "    pd.DataFrame([bias_score(\"GGG like XXX.\", [male_plural_words, female_plural_words], w) for w in science_words]),\n",
    "])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3348654310593744"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"bias\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>bias_prior_corrected</th>\n",
       "      <th>prior_correction</th>\n",
       "      <th>stimulus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.354761</td>\n",
       "      <td>-0.312276</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>poetry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.062777</td>\n",
       "      <td>-0.729814</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.088697</td>\n",
       "      <td>-0.578340</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.626061</td>\n",
       "      <td>-0.040976</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>literature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.306323</td>\n",
       "      <td>-0.360714</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>novels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.970464</td>\n",
       "      <td>0.303426</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>symphony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.195014</td>\n",
       "      <td>-0.472023</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.375476</td>\n",
       "      <td>-0.291562</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>sculptures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.322519</td>\n",
       "      <td>-0.976634</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>poetry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.480285</td>\n",
       "      <td>-1.134400</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.050046</td>\n",
       "      <td>-1.704161</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.247654</td>\n",
       "      <td>-0.901769</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>literature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.250756</td>\n",
       "      <td>-0.904871</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>novels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.487095</td>\n",
       "      <td>-1.141210</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>symphony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.304311</td>\n",
       "      <td>-1.958426</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.013455</td>\n",
       "      <td>-0.667570</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>sculptures</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bias  bias_prior_corrected  prior_correction    stimulus\n",
       "0  0.354761             -0.312276          0.667037      poetry\n",
       "1 -0.062777             -0.729814          0.667037         art\n",
       "2  0.088697             -0.578340          0.667037       dance\n",
       "3  0.626061             -0.040976          0.667037  literature\n",
       "4  0.306323             -0.360714          0.667037      novels\n",
       "5  0.970464              0.303426          0.667037    symphony\n",
       "6  0.195014             -0.472023          0.667037       drama\n",
       "7  0.375476             -0.291562          0.667037  sculptures\n",
       "0 -0.322519             -0.976634          0.654115      poetry\n",
       "1 -0.480285             -1.134400          0.654115         art\n",
       "2 -1.050046             -1.704161          0.654115       dance\n",
       "3 -0.247654             -0.901769          0.654115  literature\n",
       "4 -0.250756             -0.904871          0.654115      novels\n",
       "5 -0.487095             -1.141210          0.654115    symphony\n",
       "6 -1.304311             -1.958426          0.654115       drama\n",
       "7 -0.013455             -0.667570          0.654115  sculptures"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.concat([\n",
    "    pd.DataFrame([bias_score(\"GGG likes XXX.\", [male_words, female_words], w) for w in art_words]),\n",
    "    pd.DataFrame([bias_score(\"GGG like XXX.\", [male_plural_words, female_plural_words], w) for w in art_words]),\n",
    "])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.08138132421756844"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"bias\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=2.120443459491572, pvalue=0.042349031478676594)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_ind(df1[\"bias_prior_corrected\"], df2[\"bias_prior_corrected\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RanksumsResult(statistic=1.997512657827684, pvalue=0.045769520813725664)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranksums(df1[\"bias_prior_corrected\"], df2[\"bias_prior_corrected\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math + Science vs. Art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>bias_prior_corrected</th>\n",
       "      <th>prior_correction</th>\n",
       "      <th>stimulus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.631545</td>\n",
       "      <td>-0.035492</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.876075</td>\n",
       "      <td>0.209037</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.546070</td>\n",
       "      <td>-0.120967</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.127346</td>\n",
       "      <td>-0.539691</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.277876</td>\n",
       "      <td>-0.389162</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>einstein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.020043</td>\n",
       "      <td>0.353006</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>nasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.982217</td>\n",
       "      <td>0.315179</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>experiments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.386326</td>\n",
       "      <td>-0.280712</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>astronomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.272837</td>\n",
       "      <td>-0.394201</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>math</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.495616</td>\n",
       "      <td>-0.171422</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>algebra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.376720</td>\n",
       "      <td>-0.290317</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>geometry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.359229</td>\n",
       "      <td>-0.307808</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>calculus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.007015</td>\n",
       "      <td>0.339978</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>equations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.119367</td>\n",
       "      <td>0.452329</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>computation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.606421</td>\n",
       "      <td>-0.060616</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>numbers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.726639</td>\n",
       "      <td>0.059602</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>addition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.023502</td>\n",
       "      <td>-0.677617</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.271394</td>\n",
       "      <td>-0.382722</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.186840</td>\n",
       "      <td>-0.840955</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.654192</td>\n",
       "      <td>-1.308307</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.031780</td>\n",
       "      <td>0.377665</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>einstein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.540941</td>\n",
       "      <td>-0.113174</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>nasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.173071</td>\n",
       "      <td>-0.481044</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>experiments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.642302</td>\n",
       "      <td>-1.296417</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>astronomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.253877</td>\n",
       "      <td>-0.907992</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>math</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.523835</td>\n",
       "      <td>-1.177950</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>algebra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.390305</td>\n",
       "      <td>-1.044420</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>geometry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.975975</td>\n",
       "      <td>-1.630090</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>calculus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.257568</td>\n",
       "      <td>-0.396547</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>equations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.318912</td>\n",
       "      <td>-0.335203</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>computation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.302348</td>\n",
       "      <td>-0.351767</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>numbers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.230889</td>\n",
       "      <td>-0.885004</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>addition</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bias  bias_prior_corrected  prior_correction     stimulus\n",
       "0   0.631545             -0.035492          0.667037      science\n",
       "1   0.876075              0.209037          0.667037   technology\n",
       "2   0.546070             -0.120967          0.667037      physics\n",
       "3   0.127346             -0.539691          0.667037    chemistry\n",
       "4   0.277876             -0.389162          0.667037     einstein\n",
       "5   1.020043              0.353006          0.667037         nasa\n",
       "6   0.982217              0.315179          0.667037  experiments\n",
       "7   0.386326             -0.280712          0.667037    astronomy\n",
       "8   0.272837             -0.394201          0.667037         math\n",
       "9   0.495616             -0.171422          0.667037      algebra\n",
       "10  0.376720             -0.290317          0.667037     geometry\n",
       "11  0.359229             -0.307808          0.667037     calculus\n",
       "12  1.007015              0.339978          0.667037    equations\n",
       "13  1.119367              0.452329          0.667037  computation\n",
       "14  0.606421             -0.060616          0.667037      numbers\n",
       "15  0.726639              0.059602          0.667037     addition\n",
       "0  -0.023502             -0.677617          0.654115      science\n",
       "1   0.271394             -0.382722          0.654115   technology\n",
       "2  -0.186840             -0.840955          0.654115      physics\n",
       "3  -0.654192             -1.308307          0.654115    chemistry\n",
       "4   1.031780              0.377665          0.654115     einstein\n",
       "5   0.540941             -0.113174          0.654115         nasa\n",
       "6   0.173071             -0.481044          0.654115  experiments\n",
       "7  -0.642302             -1.296417          0.654115    astronomy\n",
       "8  -0.253877             -0.907992          0.654115         math\n",
       "9  -0.523835             -1.177950          0.654115      algebra\n",
       "10 -0.390305             -1.044420          0.654115     geometry\n",
       "11 -0.975975             -1.630090          0.654115     calculus\n",
       "12  0.257568             -0.396547          0.654115    equations\n",
       "13  0.318912             -0.335203          0.654115  computation\n",
       "14  0.302348             -0.351767          0.654115      numbers\n",
       "15 -0.230889             -0.885004          0.654115     addition"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.concat([\n",
    "    pd.DataFrame([bias_score(\"GGG likes XXX.\", [male_words, female_words], w) for w in science_words + math_words]),\n",
    "    pd.DataFrame([bias_score(\"GGG like XXX.\", [male_plural_words, female_plural_words], w) for w in science_words + math_words])    \n",
    "])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>bias_prior_corrected</th>\n",
       "      <th>prior_correction</th>\n",
       "      <th>stimulus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.354761</td>\n",
       "      <td>-0.312276</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>poetry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.062777</td>\n",
       "      <td>-0.729814</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.088697</td>\n",
       "      <td>-0.578340</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.626061</td>\n",
       "      <td>-0.040976</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>literature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.306323</td>\n",
       "      <td>-0.360714</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>novels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.970464</td>\n",
       "      <td>0.303426</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>symphony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.195014</td>\n",
       "      <td>-0.472023</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.375476</td>\n",
       "      <td>-0.291562</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>sculptures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.322519</td>\n",
       "      <td>-0.976634</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>poetry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.480285</td>\n",
       "      <td>-1.134400</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.050046</td>\n",
       "      <td>-1.704161</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.247654</td>\n",
       "      <td>-0.901769</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>literature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.250756</td>\n",
       "      <td>-0.904871</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>novels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.487095</td>\n",
       "      <td>-1.141210</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>symphony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.304311</td>\n",
       "      <td>-1.958426</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.013455</td>\n",
       "      <td>-0.667570</td>\n",
       "      <td>0.654115</td>\n",
       "      <td>sculptures</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bias  bias_prior_corrected  prior_correction    stimulus\n",
       "0  0.354761             -0.312276          0.667037      poetry\n",
       "1 -0.062777             -0.729814          0.667037         art\n",
       "2  0.088697             -0.578340          0.667037       dance\n",
       "3  0.626061             -0.040976          0.667037  literature\n",
       "4  0.306323             -0.360714          0.667037      novels\n",
       "5  0.970464              0.303426          0.667037    symphony\n",
       "6  0.195014             -0.472023          0.667037       drama\n",
       "7  0.375476             -0.291562          0.667037  sculptures\n",
       "0 -0.322519             -0.976634          0.654115      poetry\n",
       "1 -0.480285             -1.134400          0.654115         art\n",
       "2 -1.050046             -1.704161          0.654115       dance\n",
       "3 -0.247654             -0.901769          0.654115  literature\n",
       "4 -0.250756             -0.904871          0.654115      novels\n",
       "5 -0.487095             -1.141210          0.654115    symphony\n",
       "6 -1.304311             -1.958426          0.654115       drama\n",
       "7 -0.013455             -0.667570          0.654115  sculptures"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.concat([\n",
    "    pd.DataFrame([bias_score(\"GGG likes XXX.\", [male_words, female_words], w) for w in art_words]),\n",
    "    pd.DataFrame([bias_score(\"GGG like XXX.\", [male_plural_words, female_plural_words], w) for w in art_words]),\n",
    "])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=2.1118572622900595, pvalue=0.04016011842334861)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_ind(df1[\"bias_prior_corrected\"], df2[\"bias_prior_corrected\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RanksumsResult(statistic=2.0339513042753175, pvalue=0.04195650543993252)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranksums(df1[\"bias_prior_corrected\"], df2[\"bias_prior_corrected\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
